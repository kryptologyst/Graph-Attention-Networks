# @package training

_target_: src.train.trainer.Trainer

# Training configuration
epochs: 200
patience: 50
min_delta: 0.001
monitor: "val_accuracy"
mode: "max"

# Optimizer
optimizer:
  _target_: torch.optim.Adam
  lr: 0.005
  weight_decay: 5e-4
  betas: [0.9, 0.999]
  eps: 1e-8

# Learning rate scheduler
scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: "max"
  factor: 0.5
  patience: 20
  min_lr: 1e-6
  verbose: true

# Loss function
loss:
  _target_: torch.nn.CrossEntropyLoss
  reduction: "mean"

# Training settings
gradient_clip_val: 1.0
accumulate_grad_batches: 1
precision: 32  # 16, 32, bf16
log_every_n_steps: 10
val_check_interval: 1.0
check_val_every_n_epoch: 1

# Checkpointing
checkpoint:
  save_top_k: 3
  save_last: true
  every_n_epochs: 10
  filename: "epoch_{epoch:03d}-val_acc_{val_accuracy:.4f}"
